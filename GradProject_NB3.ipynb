{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle('./features_flattened.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>r_std</th>\n",
       "      <th>g_mean</th>\n",
       "      <th>g_std</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>b_std</th>\n",
       "      <th>luminance_mean</th>\n",
       "      <th>luminance_std</th>\n",
       "      <th>...</th>\n",
       "      <th>brief</th>\n",
       "      <th>orb</th>\n",
       "      <th>sift_kp</th>\n",
       "      <th>surf_kp</th>\n",
       "      <th>canny_edges</th>\n",
       "      <th>prewitt_h</th>\n",
       "      <th>prewitt_v</th>\n",
       "      <th>binarize</th>\n",
       "      <th>harris</th>\n",
       "      <th>shi_tomasi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195816</td>\n",
       "      <td>2.426829</td>\n",
       "      <td>183.355727</td>\n",
       "      <td>56.406650</td>\n",
       "      <td>176.750337</td>\n",
       "      <td>64.039966</td>\n",
       "      <td>149.151581</td>\n",
       "      <td>79.648356</td>\n",
       "      <td>166.791454</td>\n",
       "      <td>53.495949</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>398</td>\n",
       "      <td>340</td>\n",
       "      <td>266</td>\n",
       "      <td>3819</td>\n",
       "      <td>-194.894118</td>\n",
       "      <td>4.385381e-15</td>\n",
       "      <td>0.513160</td>\n",
       "      <td>121.392454</td>\n",
       "      <td>125.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221352</td>\n",
       "      <td>2.179348</td>\n",
       "      <td>210.739822</td>\n",
       "      <td>55.293247</td>\n",
       "      <td>189.280101</td>\n",
       "      <td>74.486619</td>\n",
       "      <td>164.805242</td>\n",
       "      <td>70.417988</td>\n",
       "      <td>181.672576</td>\n",
       "      <td>56.847182</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>413</td>\n",
       "      <td>207</td>\n",
       "      <td>203</td>\n",
       "      <td>1817</td>\n",
       "      <td>-34.841830</td>\n",
       "      <td>-1.143882e+02</td>\n",
       "      <td>0.842771</td>\n",
       "      <td>115.469323</td>\n",
       "      <td>160.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194535</td>\n",
       "      <td>2.381818</td>\n",
       "      <td>170.123787</td>\n",
       "      <td>64.391428</td>\n",
       "      <td>147.788681</td>\n",
       "      <td>68.085443</td>\n",
       "      <td>111.753798</td>\n",
       "      <td>89.914294</td>\n",
       "      <td>145.131762</td>\n",
       "      <td>56.089846</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>392</td>\n",
       "      <td>466</td>\n",
       "      <td>317</td>\n",
       "      <td>3755</td>\n",
       "      <td>178.556863</td>\n",
       "      <td>3.996803e-14</td>\n",
       "      <td>0.227126</td>\n",
       "      <td>93.911721</td>\n",
       "      <td>142.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200430</td>\n",
       "      <td>2.311765</td>\n",
       "      <td>152.159752</td>\n",
       "      <td>64.525514</td>\n",
       "      <td>132.648316</td>\n",
       "      <td>62.769907</td>\n",
       "      <td>77.917303</td>\n",
       "      <td>83.412773</td>\n",
       "      <td>129.573314</td>\n",
       "      <td>53.570175</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>396</td>\n",
       "      <td>575</td>\n",
       "      <td>382</td>\n",
       "      <td>5270</td>\n",
       "      <td>-252.338562</td>\n",
       "      <td>2.062941e+02</td>\n",
       "      <td>0.212932</td>\n",
       "      <td>110.053966</td>\n",
       "      <td>126.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208560</td>\n",
       "      <td>2.244318</td>\n",
       "      <td>147.397886</td>\n",
       "      <td>73.855439</td>\n",
       "      <td>150.504790</td>\n",
       "      <td>71.385855</td>\n",
       "      <td>86.252963</td>\n",
       "      <td>94.391311</td>\n",
       "      <td>138.168607</td>\n",
       "      <td>62.001119</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>407</td>\n",
       "      <td>592</td>\n",
       "      <td>431</td>\n",
       "      <td>4616</td>\n",
       "      <td>-380.200000</td>\n",
       "      <td>-2.003953e-14</td>\n",
       "      <td>0.247828</td>\n",
       "      <td>114.599032</td>\n",
       "      <td>99.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     size  aspect_ratio      r_mean      r_std      g_mean      g_std  \\\n",
       "0  195816      2.426829  183.355727  56.406650  176.750337  64.039966   \n",
       "1  221352      2.179348  210.739822  55.293247  189.280101  74.486619   \n",
       "2  194535      2.381818  170.123787  64.391428  147.788681  68.085443   \n",
       "3  200430      2.311765  152.159752  64.525514  132.648316  62.769907   \n",
       "4  208560      2.244318  147.397886  73.855439  150.504790  71.385855   \n",
       "\n",
       "       b_mean      b_std  luminance_mean  luminance_std  ...  brief  orb  \\\n",
       "0  149.151581  79.648356      166.791454      53.495949  ...     38  398   \n",
       "1  164.805242  70.417988      181.672576      56.847182  ...     52  413   \n",
       "2  111.753798  89.914294      145.131762      56.089846  ...     25  392   \n",
       "3   77.917303  83.412773      129.573314      53.570175  ...     32  396   \n",
       "4   86.252963  94.391311      138.168607      62.001119  ...     36  407   \n",
       "\n",
       "   sift_kp  surf_kp  canny_edges   prewitt_h     prewitt_v  binarize  \\\n",
       "0      340      266         3819 -194.894118  4.385381e-15  0.513160   \n",
       "1      207      203         1817  -34.841830 -1.143882e+02  0.842771   \n",
       "2      466      317         3755  178.556863  3.996803e-14  0.227126   \n",
       "3      575      382         5270 -252.338562  2.062941e+02  0.212932   \n",
       "4      592      431         4616 -380.200000 -2.003953e-14  0.247828   \n",
       "\n",
       "       harris  shi_tomasi  \n",
       "0  121.392454      125.92  \n",
       "1  115.469323      160.38  \n",
       "2   93.911721      142.00  \n",
       "3  110.053966      126.54  \n",
       "4  114.599032       99.30  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = features.drop([\"categories\",\"label\"], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Part Three: Classifier training and performance assessment. </h2>\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, labels):\n",
    "    ss= StandardScaler()\n",
    "    df_stand = ss.fit_transform(df.values)\n",
    "    X= df_stand\n",
    "    y=labels\n",
    "#     y = features['label'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "    y_train=y_train.astype('int')\n",
    "    y_test = y_test.astype('int')\n",
    "    return X_train, X_test, y_train, y_test\n",
    "#Split the data into a training set, and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_accuracy(name_string, model):\n",
    "        # generate predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(name_string+ \" \" +'Model accuracy is: ', accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, X_train, Y_train):\n",
    "    # Computes mean of 5 cross validation on accuracy\n",
    "    \n",
    "    '''\n",
    "    Split the training data into 5 subsets.\n",
    "    For each subset, \n",
    "        fit a model holding out that subset\n",
    "        compute the accuracy on that subset (the validation set)\n",
    "    Return the average MSE of these 5 folds.\n",
    "\n",
    "    Args:\n",
    "        model: an sklearn model with fit and predict functions \n",
    "        X_train (data_frame): Training data\n",
    "        Y_train (data_frame): Label \n",
    "\n",
    "    Return:\n",
    "        the average validation accuracy for the 5 splits.\n",
    "    '''\n",
    "    kf = KFold(n_splits=5)\n",
    "    validation_accuracy = []\n",
    "    \n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        # split the data\n",
    "        split_X_train, split_X_valid = X_train[train_idx] , X_train[valid_idx]\n",
    "        split_Y_train, split_Y_valid = Y_train[train_idx] , Y_train[valid_idx]\n",
    "        # Fit the model on the training split\n",
    "        model.fit(split_X_train, split_Y_train)\n",
    "        \n",
    "        # Compute the RMSE on the validation split\n",
    "        accuracy = accuracy_score(split_Y_valid, model.predict(split_X_valid))\n",
    "\n",
    "\n",
    "        validation_accuracy.append(accuracy)\n",
    "        \n",
    "    return np.mean(validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMinDiff(arr): \n",
    "    #Returns minimum difference of an array and its index\n",
    "    # Initialize difference as infinite \n",
    "    diff = 10**20\n",
    "    index = []\n",
    "      \n",
    "    # Find the min diff by comparing difference \n",
    "    # of all possible pairs in given array \n",
    "    for i in range(0,len(arr)): \n",
    "        for j in range(i+1,len(arr)): \n",
    "            if abs(arr[i]-arr[j]) < diff: \n",
    "                diff = abs(arr[i] - arr[j]) \n",
    "                index = [i+1,j+1]\n",
    "  \n",
    "    # Return min diff \n",
    "    return diff, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMaxDiff(arr): \n",
    "    #Returns maximum difference of an array and its index\n",
    "    # Initialize difference as infinite \n",
    "    diff = 0\n",
    "    index=[]\n",
    "      \n",
    "    # Find the min diff by comparing difference \n",
    "    # of all possible pairs in given array \n",
    "    for i in range(13,len(arr)): \n",
    "        for j in range(i+1,len(arr)): \n",
    "            if abs(arr[i]-arr[j]) > diff: \n",
    "                diff = abs(arr[i] - arr[j])    \n",
    "                index = [i+1,j+1]\n",
    "                \n",
    "  \n",
    "    # Return max diff \n",
    "    return diff, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(train, features['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying first 1 features\n",
      "\tAccuracy: 0.17083333333333334\n",
      "Trying first 2 features\n",
      "\tAccuracy: 0.22000000000000003\n",
      "Trying first 3 features\n",
      "\tAccuracy: 0.29333333333333333\n",
      "Trying first 4 features\n",
      "\tAccuracy: 0.2916666666666667\n",
      "Trying first 5 features\n",
      "\tAccuracy: 0.29500000000000004\n",
      "Trying first 6 features\n",
      "\tAccuracy: 0.3125\n",
      "Trying first 7 features\n",
      "\tAccuracy: 0.33166666666666667\n",
      "Trying first 8 features\n",
      "\tAccuracy: 0.3308333333333333\n",
      "Trying first 9 features\n",
      "\tAccuracy: 0.32666666666666666\n",
      "Trying first 10 features\n",
      "\tAccuracy: 0.32333333333333336\n",
      "Trying first 11 features\n",
      "\tAccuracy: 0.31916666666666665\n",
      "Trying first 12 features\n",
      "\tAccuracy: 0.31999999999999995\n",
      "Trying first 13 features\n",
      "\tAccuracy: 0.33916666666666667\n",
      "Trying first 14 features\n",
      "\tAccuracy: 0.34249999999999997\n",
      "Trying first 15 features\n",
      "\tAccuracy: 0.34249999999999997\n",
      "Trying first 16 features\n",
      "\tAccuracy: 0.34833333333333333\n",
      "Trying first 17 features\n",
      "\tAccuracy: 0.36333333333333334\n",
      "Trying first 18 features\n",
      "\tAccuracy: 0.36083333333333334\n",
      "Trying first 19 features\n",
      "\tAccuracy: 0.3591666666666667\n",
      "Trying first 20 features\n",
      "\tAccuracy: 0.3616666666666667\n",
      "Trying first 21 features\n",
      "\tAccuracy: 0.3508333333333334\n",
      "Trying first 22 features\n",
      "\tAccuracy: 0.355\n",
      "Trying first 23 features\n",
      "\tAccuracy: 0.35583333333333333\n",
      "Trying first 24 features\n",
      "\tAccuracy: 0.3633333333333334\n",
      "Trying first 25 features\n",
      "\tAccuracy: 0.36583333333333334\n",
      "SVM best number of features 25\n",
      "KFold Validation Accuracy 0.36583333333333334\n",
      "SVM Test Accuracy 0.39867109634551495\n",
      "Minimum increase in accuracy is from features:  [14, 15]\n",
      "Maximum increase in accuracy is from features:  [14, 25]\n"
     ]
    }
   ],
   "source": [
    "# This code computes 5 fold cross validation on an SVM where it is trained\n",
    "# on models with each successive feature. Finds how many features will result\n",
    "# in the highest accuracy, and predicts on the test set with a model that is \n",
    "# trained on the optimal number of features\n",
    "\n",
    "\n",
    "svm = SVC()\n",
    "range_of_num_features = range(1,X_train.shape[1]+1)\n",
    "accuracy_SVM=[]\n",
    "for N in range_of_num_features:\n",
    "    print(f\"Trying first {N} features\")   \n",
    "    # compute the cross validation accuracy\n",
    "    accuracy = compute_accuracy(svm, X_train[:,:N],y_train)\n",
    "    \n",
    "    print(\"\\tAccuracy:\", accuracy)\n",
    "    accuracy_SVM.append(accuracy)\n",
    "\n",
    "best_num_features_SVM = np.argmax(accuracy_SVM) + 1\n",
    "best_accuracy_SVM = accuracy_SVM[best_num_features_SVM-1]\n",
    "\n",
    "# Fit SVM Model\n",
    "svm.fit(X_train[:, :best_num_features_SVM], y_train)\n",
    "\n",
    "# Predict points from the test set and calculate the accuracy\n",
    "test_accuracy_SVM = accuracy_score(y_test, svm.predict(X_test[:, :best_num_features_SVM]))\n",
    "\n",
    "# Minimum increase in accuracy\n",
    "diff, index = findMinDiff(accuracy_SVM)\n",
    "diff_max, index_max = findMaxDiff(accuracy_SVM)\n",
    "\n",
    "print(\"SVM best number of features\", best_num_features_SVM)\n",
    "print(\"KFold Validation Accuracy\", best_accuracy_SVM)\n",
    "print(\"SVM Test Accuracy\", test_accuracy_SVM)\n",
    "print(\"Minimum increase in accuracy is from features: \", index)\n",
    "print(\"Maximum increase in accuracy is from features: \", index_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model accuracy is:  0.42857142857142855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final SVM model\n",
    "svm = SVC(kernel='linear', C=10,probability=True, random_state=42)\n",
    "#C=1: Accuracy 0.0.40863787375415284\n",
    "#C=10: Accuracy 0.42857142857142855\n",
    "#C=50: Accuracy 0.40863787375415284\n",
    "#C=100: Accuracy 0.4019933554817276\n",
    "\n",
    "# SVM Gaussian Model accuracy is:  0.39867109634551495\n",
    "# SVM Sigmoid Model accuracy is:  0.30564784053156147\n",
    "# SVM Poly Model accuracy is:  0.20930232558139536\n",
    "\n",
    "# fit model\n",
    "svm.fit(X_train, y_train)\n",
    "pred_accuracy('SVM', svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model accuracy is:  0.34551495016611294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34551495016611294"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "pred_accuracy(\"KNN\",knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying first 1 features\n",
      "\tAccuracy: 0.19833333333333333\n",
      "Trying first 2 features\n",
      "\tAccuracy: 0.23166666666666663\n",
      "Trying first 3 features\n",
      "\tAccuracy: 0.25\n",
      "Trying first 4 features\n",
      "\tAccuracy: 0.26\n",
      "Trying first 5 features\n",
      "\tAccuracy: 0.25166666666666665\n",
      "Trying first 6 features\n",
      "\tAccuracy: 0.2541666666666667\n",
      "Trying first 7 features\n",
      "\tAccuracy: 0.2633333333333333\n",
      "Trying first 8 features\n",
      "\tAccuracy: 0.27749999999999997\n",
      "Trying first 9 features\n",
      "\tAccuracy: 0.2733333333333333\n",
      "Trying first 10 features\n",
      "\tAccuracy: 0.27166666666666667\n",
      "Trying first 11 features\n",
      "\tAccuracy: 0.2675\n",
      "Trying first 12 features\n",
      "\tAccuracy: 0.2783333333333334\n",
      "Trying first 13 features\n",
      "\tAccuracy: 0.2816666666666666\n",
      "Trying first 14 features\n",
      "\tAccuracy: 0.275\n",
      "Trying first 15 features\n",
      "\tAccuracy: 0.2816666666666666\n",
      "Trying first 16 features\n",
      "\tAccuracy: 0.26833333333333337\n",
      "Trying first 17 features\n",
      "\tAccuracy: 0.2975\n",
      "Trying first 18 features\n",
      "\tAccuracy: 0.29999999999999993\n",
      "Trying first 19 features\n",
      "\tAccuracy: 0.3\n",
      "Trying first 20 features\n",
      "\tAccuracy: 0.2975\n",
      "Trying first 21 features\n",
      "\tAccuracy: 0.29416666666666663\n",
      "Trying first 22 features\n",
      "\tAccuracy: 0.2916666666666667\n",
      "Trying first 23 features\n",
      "\tAccuracy: 0.2925\n",
      "Trying first 24 features\n",
      "\tAccuracy: 0.29833333333333334\n",
      "Trying first 25 features\n",
      "\tAccuracy: 0.30249999999999994\n",
      "KNN best number of features 25\n",
      "KFold Validation Accuracy 0.30249999999999994\n",
      "KNN Test Accuracy 0.34551495016611294\n",
      "Minimum increase in accuracy is from features:  [13, 15]\n",
      "Maximum increase in accuracy is from features:  [16, 25]\n"
     ]
    }
   ],
   "source": [
    "range_of_num_features = range(1,X_train.shape[1]+1)\n",
    "accuracy_KNN=[]\n",
    "for N in range_of_num_features:\n",
    "    print(f\"Trying first {N} features\")   \n",
    "    # compute the cross validation accuracy\n",
    "    accuracy = compute_accuracy(knn, X_train[:,:N],y_train)\n",
    "    \n",
    "    print(\"\\tAccuracy:\", accuracy)\n",
    "    accuracy_KNN.append(accuracy)\n",
    "\n",
    "best_num_features_KNN = np.argmax(accuracy_KNN) + 1\n",
    "best_accuracy_KNN = accuracy_KNN[best_num_features_KNN-1]\n",
    "\n",
    "# Fit KNN Model\n",
    "knn.fit(X_train[:, :best_num_features_KNN], y_train)\n",
    "\n",
    "# Predict points from the test set and calculate the accuracy\n",
    "test_accuracy_KNN = accuracy_score(y_test, knn.predict(X_test[:, :best_num_features_KNN]))\n",
    "\n",
    "# Minimum increase in accuracy\n",
    "diff_min, index_min = findMinDiff(accuracy_KNN)\n",
    "diff_max, index_max = findMaxDiff(accuracy_KNN)\n",
    "\n",
    "print(\"KNN best number of features\", best_num_features_KNN)\n",
    "print(\"KFold Validation Accuracy\", best_accuracy_KNN)\n",
    "print(\"KNN Test Accuracy\", test_accuracy_KNN)\n",
    "print(\"Minimum increase in accuracy is from features: \", index_min)\n",
    "print(\"Maximum increase in accuracy is from features: \", index_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model accuracy is:  0.2956810631229236\n",
      "KNN Model accuracy is:  0.2724252491694352\n",
      "KNN Model accuracy is:  0.3089700996677741\n",
      "KNN Model accuracy is:  0.32558139534883723\n",
      "KNN Model accuracy is:  0.34551495016611294\n",
      "KNN Model accuracy is:  0.3388704318936877\n",
      "KNN Model accuracy is:  0.3687707641196013\n",
      "KNN Model accuracy is:  0.3754152823920266\n",
      "KNN Model accuracy is:  0.38205980066445183\n",
      "KNN Model accuracy is:  0.38205980066445183\n",
      "KNN Model accuracy is:  0.37209302325581395\n",
      "KNN Model accuracy is:  0.36212624584717606\n",
      "KNN Model accuracy is:  0.36212624584717606\n",
      "KNN Model accuracy is:  0.3687707641196013\n",
      "KNN Model accuracy is:  0.3554817275747508\n",
      "KNN Model accuracy is:  0.36212624584717606\n",
      "KNN Model accuracy is:  0.3654485049833887\n",
      "KNN Model accuracy is:  0.3521594684385382\n",
      "KNN Model accuracy is:  0.34551495016611294\n"
     ]
    }
   ],
   "source": [
    "n_neighbors= np.arange(1,20)\n",
    "accuracies=[]\n",
    "for n in n_neighbors:\n",
    "    kn= KNeighborsClassifier(n_neighbors=n)\n",
    "    kn.fit(X_train, y_train)\n",
    "    train_pred = kn.predict(X_train)\n",
    "#     print(n)\n",
    "    n = pred_accuracy(\"KNN\",kn)\n",
    "    accuracies.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracies)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"KNN\")\n",
    "plt.title(\"KNN Model Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model accuracy is:  0.38205980066445183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38205980066445183"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=10,p=2)\n",
    "knn.fit(X_train, y_train)\n",
    "pred_accuracy(\"KNN\",knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying first 1 features\n",
      "\tAccuracy: 0.18166666666666664\n",
      "Trying first 2 features\n",
      "\tAccuracy: 0.2333333333333333\n",
      "Trying first 3 features\n",
      "\tAccuracy: 0.29\n",
      "Trying first 4 features\n",
      "\tAccuracy: 0.2983333333333333\n",
      "Trying first 5 features\n",
      "\tAccuracy: 0.315\n",
      "Trying first 6 features\n",
      "\tAccuracy: 0.33083333333333337\n",
      "Trying first 7 features\n",
      "\tAccuracy: 0.345\n",
      "Trying first 8 features\n",
      "\tAccuracy: 0.3516666666666667\n",
      "Trying first 9 features\n",
      "\tAccuracy: 0.3516666666666667\n",
      "Trying first 10 features\n",
      "\tAccuracy: 0.36583333333333334\n",
      "Trying first 11 features\n",
      "\tAccuracy: 0.36583333333333334\n",
      "Trying first 12 features\n",
      "\tAccuracy: 0.3616666666666667\n",
      "Trying first 13 features\n",
      "\tAccuracy: 0.3616666666666667\n",
      "Trying first 14 features\n",
      "\tAccuracy: 0.37583333333333335\n",
      "Trying first 15 features\n",
      "\tAccuracy: 0.3825\n",
      "Trying first 16 features\n",
      "\tAccuracy: 0.38416666666666666\n",
      "Trying first 17 features\n",
      "\tAccuracy: 0.4083333333333333\n",
      "Trying first 18 features\n",
      "\tAccuracy: 0.40166666666666667\n",
      "Trying first 19 features\n",
      "\tAccuracy: 0.3991666666666666\n",
      "Trying first 20 features\n",
      "\tAccuracy: 0.4166666666666667\n",
      "Trying first 21 features\n",
      "\tAccuracy: 0.4141666666666667\n",
      "Trying first 22 features\n",
      "\tAccuracy: 0.4125\n",
      "Trying first 23 features\n",
      "\tAccuracy: 0.4141666666666667\n",
      "Trying first 24 features\n",
      "\tAccuracy: 0.41583333333333333\n",
      "Trying first 25 features\n",
      "\tAccuracy: 0.4149999999999999\n",
      "Logistic Regression best number of features 20\n",
      "KFold Validation Accuracy 0.4166666666666667\n",
      "Logistic Regression Test Accuracy 0.42524916943521596\n",
      "Minimum increase in accuracy is from features:  [8, 9]\n",
      "Maximum increase in accuracy is from features:  [14, 20]\n"
     ]
    }
   ],
   "source": [
    "range_of_num_features = range(1,X_train.shape[1]+1)\n",
    "accuracy_LR=[]\n",
    "for N in range_of_num_features:\n",
    "    print(f\"Trying first {N} features\")   \n",
    "    # compute the cross validation accuracy\n",
    "    accuracy = compute_accuracy(logisticRegr, X_train[:,:N],y_train)\n",
    "    \n",
    "    print(\"\\tAccuracy:\", accuracy)\n",
    "    accuracy_LR.append(accuracy)\n",
    "\n",
    "best_num_features_LR = np.argmax(accuracy_LR) + 1\n",
    "best_accuracy_LR = accuracy_LR[best_num_features_LR-1]\n",
    "\n",
    "# Fit Logistic Regression Model\n",
    "logisticRegr.fit(X_train[:, :best_num_features_LR], y_train)\n",
    "\n",
    "# Predict points from the test set and calculate the accuracy\n",
    "test_accuracy_LR = accuracy_score(y_test, logisticRegr.predict(X_test[:, :best_num_features_LR]))\n",
    "\n",
    "# Minimum increase in accuracy\n",
    "diff, index = findMinDiff(accuracy_LR)\n",
    "diff_max, index_max = findMaxDiff(accuracy_LR)\n",
    "\n",
    "print(\"Logistic Regression best number of features\", best_num_features_LR)\n",
    "print(\"KFold Validation Accuracy\", best_accuracy_LR)\n",
    "print(\"Logistic Regression Test Accuracy\", test_accuracy_LR)\n",
    "print(\"Minimum increase in accuracy is from features: \", index)\n",
    "print(\"Maximum increase in accuracy is from features: \", index_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Model accuracy is:  0.3920265780730897\n",
      "Logistic Model accuracy is:  0.3953488372093023\n",
      "Logistic Model accuracy is:  0.4053156146179402\n",
      "Logistic Model accuracy is:  0.40863787375415284\n",
      "Logistic Model accuracy is:  0.4053156146179402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4053156146179402"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression(C=5,penalty='l1')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "pred_accuracy(\"Logistic\",logisticRegr)\n",
    "\n",
    "logisticRegr = LogisticRegression(C=10,penalty='l1')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "pred_accuracy(\"Logistic\",logisticRegr)\n",
    "\n",
    "logisticRegr = LogisticRegression(C=20,penalty='l1')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "pred_accuracy(\"Logistic\",logisticRegr)\n",
    "\n",
    "logisticRegr = LogisticRegression(C=25,penalty='l1')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "pred_accuracy(\"Logistic\",logisticRegr)\n",
    "\n",
    "logisticRegr = LogisticRegression(C=30,penalty='l1')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "pred_accuracy(\"Logistic\",logisticRegr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Model accuracy is:  0.38870431893687707\n",
      "Logistic Model accuracy is:  0.4053156146179402\n",
      "Logistic Model accuracy is:  0.40863787375415284\n",
      "Logistic Model accuracy is:  0.4152823920265781\n",
      "Logistic Model accuracy is:  0.4152823920265781\n",
      "Logistic Model accuracy is:  0.4119601328903654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4119601328903654"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression(C=5,penalty='l2')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "pred_accuracy(\"Logistic\",logisticRegr)\n",
    "\n",
    "logisticRegr = LogisticRegression(C=10,penalty='l2')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "pred_accuracy(\"Logistic\",logisticRegr)\n",
    "\n",
    "logisticRegr = LogisticRegression(C=15,penalty='l2')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "pred_accuracy(\"Logistic\",logisticRegr)\n",
    "\n",
    "logisticRegr = LogisticRegression(C=20,penalty='l2')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "pred_accuracy(\"Logistic\",logisticRegr)\n",
    "\n",
    "logisticRegr = LogisticRegression(C=25,penalty='l2')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "pred_accuracy(\"Logistic\",logisticRegr)\n",
    "\n",
    "logisticRegr = LogisticRegression(C=30,penalty='l2')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "pred_accuracy(\"Logistic\",logisticRegr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Model accuracy is:  0.4152823920265781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4152823920265781"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Logistic Regression\n",
    "\n",
    "logisticRegr = LogisticRegression(C=20,penalty='l2')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "pred_accuracy(\"Logistic\",logisticRegr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Classification Tree\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying first 1 features\n",
      "\tAccuracy: 0.19166666666666668\n",
      "Trying first 2 features\n",
      "\tAccuracy: 0.26583333333333337\n",
      "Trying first 3 features\n",
      "\tAccuracy: 0.29083333333333333\n",
      "Trying first 4 features\n",
      "\tAccuracy: 0.29\n",
      "Trying first 5 features\n",
      "\tAccuracy: 0.28250000000000003\n",
      "Trying first 6 features\n",
      "\tAccuracy: 0.2866666666666667\n",
      "Trying first 7 features\n",
      "\tAccuracy: 0.3175\n",
      "Trying first 8 features\n",
      "\tAccuracy: 0.31999999999999995\n",
      "Trying first 9 features\n",
      "\tAccuracy: 0.31999999999999995\n",
      "Trying first 10 features\n",
      "\tAccuracy: 0.32416666666666666\n",
      "Trying first 11 features\n",
      "\tAccuracy: 0.3075\n",
      "Trying first 12 features\n",
      "\tAccuracy: 0.3083333333333333\n",
      "Trying first 13 features\n",
      "\tAccuracy: 0.3083333333333333\n",
      "Trying first 14 features\n",
      "\tAccuracy: 0.31\n",
      "Trying first 15 features\n",
      "\tAccuracy: 0.31\n",
      "Trying first 16 features\n",
      "\tAccuracy: 0.3066666666666667\n",
      "Trying first 17 features\n",
      "\tAccuracy: 0.30500000000000005\n",
      "Trying first 18 features\n",
      "\tAccuracy: 0.3016666666666667\n",
      "Trying first 19 features\n",
      "\tAccuracy: 0.29833333333333334\n",
      "Trying first 20 features\n",
      "\tAccuracy: 0.30666666666666664\n",
      "Trying first 21 features\n",
      "\tAccuracy: 0.30666666666666664\n",
      "Trying first 22 features\n",
      "\tAccuracy: 0.30666666666666664\n",
      "Trying first 23 features\n",
      "\tAccuracy: 0.30250000000000005\n",
      "Trying first 24 features\n",
      "\tAccuracy: 0.3041666666666667\n",
      "Trying first 25 features\n",
      "\tAccuracy: 0.2958333333333333\n",
      "Classification Tree best number of features 10\n",
      "KFold Validation Accuracy 0.32416666666666666\n",
      "Classification Tree Test Accuracy 0.31561461794019935\n",
      "Minimum increase in accuracy is from features:  [8, 9]\n",
      "Maximum increase in accuracy is from features:  [14, 25]\n"
     ]
    }
   ],
   "source": [
    "range_of_num_features = range(1,X_train.shape[1]+1)\n",
    "accuracy_dtc=[]\n",
    "for N in range_of_num_features:\n",
    "    print(f\"Trying first {N} features\")   \n",
    "    # compute the cross validation accuracy\n",
    "    accuracy = compute_accuracy(dtc, X_train[:,:N],y_train)\n",
    "    \n",
    "    print(\"\\tAccuracy:\", accuracy)\n",
    "    accuracy_dtc.append(accuracy)\n",
    "\n",
    "best_num_features_dtc = np.argmax(accuracy_dtc) + 1\n",
    "best_accuracy_dtc = accuracy_dtc[best_num_features_dtc-1]\n",
    "\n",
    "# Fit Classification Tree Model\n",
    "dtc.fit(X_train[:, :best_num_features_dtc], y_train)\n",
    "\n",
    "# Predict points from the test set and calculate the accuracy\n",
    "test_accuracy_dtc = accuracy_score(y_test, dtc.predict(X_test[:, :best_num_features_dtc]))\n",
    "\n",
    "# Minimum increase in accuracy\n",
    "diff, index = findMinDiff(accuracy_dtc)\n",
    "diff_max, index_max = findMaxDiff(accuracy_dtc)\n",
    "\n",
    "\n",
    "print(\"Classification Tree best number of features\", best_num_features_dtc)\n",
    "print(\"KFold Validation Accuracy\", best_accuracy_dtc)\n",
    "print(\"Classification Tree Test Accuracy\", test_accuracy_dtc)\n",
    "print(\"Minimum increase in accuracy is from features: \", index)\n",
    "print(\"Maximum increase in accuracy is from features: \", index_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model accuracy is:  0.30564784053156147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30564784053156147"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final DTC\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=16,min_samples_leaf=.04)\n",
    "dtc = dtc.fit(X_train, y_train)\n",
    "pred_accuracy(\"Decision Tree\",dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFM Model accuracy is:  0.3488372093023256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3488372093023256"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "pred_accuracy(\"RFM\",rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "      estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                       criterion='gini', max_depth=None,\n",
       "                                       max_features='auto', max_leaf_nodes=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       n_estimators='warn', n_jobs=None,\n",
       "                                       oob_score=False, random_state=101,\n",
       "                                       verbose=0, warm_start=False),\n",
       "      min_features_to_select=1, n_jobs=None, scoring='accuracy', step=1,\n",
       "      verbose=0)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying Recursive Feature Elimination for Feature Selection\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=101)\n",
    "rfecv = RFECV(estimator=rfc, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF w RFE Model accuracy is:  0.3023255813953488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3023255813953488"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_accuracy(\"RF w RFE\",rfecv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFM Model accuracy is:  0.2823920265780731\n",
      "RFM Model accuracy is:  0.2757475083056478\n",
      "RFM Model accuracy is:  0.292358803986711\n",
      "RFM Model accuracy is:  0.29900332225913623\n",
      "RFM Model accuracy is:  0.33554817275747506\n",
      "RFM Model accuracy is:  0.3754152823920266\n",
      "RFM Model accuracy is:  0.4119601328903654\n",
      "RFM Model accuracy is:  0.4318936877076412\n",
      "RFM Model accuracy is:  0.43853820598006643\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
    "\n",
    "accuracies = []\n",
    "for estimator in n_estimators:\n",
    "    rf = RandomForestClassifier(n_estimators=estimator, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    train_pred = rf.predict(X_train)\n",
    "    accuracy = accuracy_score(y_train, train_pred)\n",
    "    accuracies.append(accuracy)\n",
    "#     print(estimator)\n",
    "    n= pred_accuracy(\"RFM\",rf)\n",
    "    accuracies.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize if desired\n",
    "# plt.plot(accuracies)\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.xlabel(\"RFM\")\n",
    "# plt.title(\"RFM iter n_estimators Model Accuracy\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFM Model accuracy is:  0.42524916943521596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42524916943521596"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final RFM\n",
    "rf = RandomForestClassifier(n_estimators=200,max_depth=10, random_state=42, max_features=5)\n",
    "rf.fit(X_train, y_train)\n",
    "pred_accuracy(\"RFM\",rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Best Model on Val Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model accuracy is:  0.42857142857142855\n",
      "KNN Model accuracy is:  0.38205980066445183\n",
      "Decision Tree Model accuracy is:  0.30564784053156147\n",
      "RFM Model accuracy is:  0.42524916943521596\n",
      "Logistic Model accuracy is:  0.4152823920265781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4152823920265781"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_accuracy('SVM', svm)\n",
    "pred_accuracy(\"KNN\",knn)\n",
    "pred_accuracy(\"Decision Tree\",dtc)\n",
    "pred_accuracy(\"RFM\",rf)\n",
    "pred_accuracy(\"Logistic\",logisticRegr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train best model\n",
    "best = SVC(kernel='linear', C=10,probability=True, random_state=42)\n",
    "best = best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>r_std</th>\n",
       "      <th>g_mean</th>\n",
       "      <th>g_std</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>b_std</th>\n",
       "      <th>luminance_mean</th>\n",
       "      <th>luminance_std</th>\n",
       "      <th>...</th>\n",
       "      <th>brief</th>\n",
       "      <th>orb</th>\n",
       "      <th>sift_kp</th>\n",
       "      <th>surf_kp</th>\n",
       "      <th>canny_edges</th>\n",
       "      <th>prewitt_h</th>\n",
       "      <th>prewitt_v</th>\n",
       "      <th>binarize</th>\n",
       "      <th>harris</th>\n",
       "      <th>shi_tomasi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1620000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>105.980433</td>\n",
       "      <td>67.205121</td>\n",
       "      <td>106.905494</td>\n",
       "      <td>65.316848</td>\n",
       "      <td>105.590887</td>\n",
       "      <td>63.113690</td>\n",
       "      <td>107.446701</td>\n",
       "      <td>56.130446</td>\n",
       "      <td>...</td>\n",
       "      <td>898</td>\n",
       "      <td>500</td>\n",
       "      <td>3970</td>\n",
       "      <td>3274</td>\n",
       "      <td>38530</td>\n",
       "      <td>-182.307190</td>\n",
       "      <td>54.364706</td>\n",
       "      <td>0.387165</td>\n",
       "      <td>136.623414</td>\n",
       "      <td>259.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1279200</td>\n",
       "      <td>1.500938</td>\n",
       "      <td>112.572315</td>\n",
       "      <td>89.033710</td>\n",
       "      <td>101.316091</td>\n",
       "      <td>78.646389</td>\n",
       "      <td>65.335870</td>\n",
       "      <td>60.860931</td>\n",
       "      <td>102.380433</td>\n",
       "      <td>67.857657</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>500</td>\n",
       "      <td>580</td>\n",
       "      <td>498</td>\n",
       "      <td>8127</td>\n",
       "      <td>-737.857516</td>\n",
       "      <td>117.811765</td>\n",
       "      <td>0.409045</td>\n",
       "      <td>106.985920</td>\n",
       "      <td>351.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      size  aspect_ratio      r_mean      r_std      g_mean      g_std  \\\n",
       "0  1620000      1.500000  105.980433  67.205121  106.905494  65.316848   \n",
       "1  1279200      1.500938  112.572315  89.033710  101.316091  78.646389   \n",
       "\n",
       "       b_mean      b_std  luminance_mean  luminance_std  ...  brief  orb  \\\n",
       "0  105.590887  63.113690      107.446701      56.130446  ...    898  500   \n",
       "1   65.335870  60.860931      102.380433      67.857657  ...     86  500   \n",
       "\n",
       "   sift_kp  surf_kp  canny_edges   prewitt_h   prewitt_v  binarize  \\\n",
       "0     3970     3274        38530 -182.307190   54.364706  0.387165   \n",
       "1      580      498         8127 -737.857516  117.811765  0.409045   \n",
       "\n",
       "       harris  shi_tomasi  \n",
       "0  136.623414      259.62  \n",
       "1  106.985920      351.28  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load in val set\n",
    "val = pd.read_pickle('./val_features.pkl') \n",
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss= StandardScaler()\n",
    "val_stand = ss.fit_transform(val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and save results\n",
    "test_prediction = best.predict(val_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  1, 15,  9, 19, 14,  8,  9,  5,  2,  9, 17,  3, 11,  3, 19, 18,\n",
       "       13, 16, 17,  4, 19,  4, 14,  5,  8,  9,  5, 13, 17, 14,  8, 13,  7,\n",
       "       16, 17, 13, 17, 17,  5, 14,  9,  8, 17,  5,  6, 17,  9, 16, 13, 14,\n",
       "        4,  4,  7, 13,  4,  9,  9, 13, 13,  9,  9, 15,  9, 11,  5, 15,  8,\n",
       "       10, 16, 17,  9,  9,  9, 15, 10,  5, 16, 14, 17, 16,  2,  4,  9, 16,\n",
       "       18,  1, 16,  5,  2, 14,  3,  3,  3,  3, 17, 14,  3, 14,  9,  9,  3,\n",
       "        3,  3, 14,  3,  3,  3, 11,  3, 12,  4,  9, 12, 12, 12, 12, 12, 12,\n",
       "       12, 12, 12, 12,  8, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 14, 12,\n",
       "       12, 12, 12, 12, 12, 12, 12,  1, 12,  1, 14, 18,  3,  9,  9,  9, 14,\n",
       "       14, 10, 15,  9,  9, 17, 13,  2,  5,  4,  7, 18,  7,  5, 17, 15, 16,\n",
       "       14, 13, 18,  9,  5, 13,  7, 10, 19, 13, 13, 13,  9, 10, 14, 13, 10,\n",
       "       14, 10,  1,  9, 19,  4, 13, 13,  8, 13,  9,  9, 13,  1,  1,  9, 15,\n",
       "        9, 18, 13,  5,  5,  9,  9,  9,  9,  6,  1,  6,  0,  0,  2,  0,  0,\n",
       "        0, 14, 14,  0,  0,  0,  0,  0,  2,  9, 17,  5,  1,  8,  5,  4, 12,\n",
       "       12, 12,  9, 12, 12, 12, 12, 14, 16, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "       12,  8, 12, 10, 10, 10, 10, 10,  1, 18, 13, 15,  8,  9, 15,  4, 16,\n",
       "        1, 10, 10, 19, 10,  4,  4,  1, 10, 13, 19,  7,  5, 13,  1, 14, 17,\n",
       "        8,  8,  3, 19, 14,  9,  9,  5,  5,  7,  7, 15, 15,  9, 12, 16, 10,\n",
       "       16,  8, 16, 16, 16, 14, 17, 16,  4,  5, 16,  4, 16, 14,  5,  3,  9,\n",
       "        3,  3,  3,  3,  3, 14, 19,  3, 16, 16,  3,  9,  3,  3,  3,  8,  1,\n",
       "       11,  5,  6, 13,  6,  1,  9, 15, 16,  5,  5, 16,  7,  1, 13,  9,  5,\n",
       "       17,  7,  8,  7, 14,  9,  9, 14, 14,  9,  5,  1, 14,  1, 17, 17, 14,\n",
       "        6,  6, 11, 17, 12,  3,  6, 11, 11,  6,  6,  5, 19,  2, 19, 14,  3,\n",
       "        9,  9,  9,  9,  9,  9,  9, 14,  9,  1,  9,  9, 15,  8,  5, 15,  9,\n",
       "        9,  9,  9,  9, 14,  1,  9,  8,  9,  9,  8, 14,  1,  9, 13,  9,  3,\n",
       "        1,  4,  9,  5,  9, 19,  9,  1,  7, 19,  9,  9,  9,  1, 14,  9,  9,\n",
       "       18,  9,  3, 19,  9,  1, 14, 16,  9, 18,  9,  9,  9, 10,  9,  9,  9,\n",
       "        3,  9,  9,  8,  1,  4, 16, 13, 13,  9, 14, 10,  9,  9,  2,  5, 10,\n",
       "        4, 10, 17,  1, 17,  4, 13, 13,  4,  4,  4,  4, 15, 19,  4,  4,  2,\n",
       "        5,  4, 14,  6,  7, 14,  9,  7,  2,  5, 14, 17,  5,  2, 17,  1, 11,\n",
       "       11, 14, 17,  6, 17,  5,  0,  0,  0,  0,  6,  2,  1,  2,  0,  0,  0,\n",
       "        0,  0,  0,  2,  0,  2,  9,  0,  0,  0,  2,  2,  2,  0,  0,  0,  0,\n",
       "       19,  0,  0,  0,  2,  0,  2,  0,  0,  4, 15, 18, 17,  7, 17, 19,  8,\n",
       "        1, 16, 14,  5,  1, 17, 10,  5,  5,  7,  9,  8, 13, 13,  1,  4, 18,\n",
       "       10,  7,  9,  8,  1, 14,  8,  4, 17, 15,  9, 17, 17,  9,  6,  6,  6,\n",
       "       11,  6,  3,  0,  6, 13,  6, 14, 11,  4,  6,  9, 17,  6,  2,  2, 19,\n",
       "        2,  6,  6,  4,  6, 11,  6, 18,  6,  6, 15,  6, 15,  9,  8, 10, 17,\n",
       "        5, 15,  7, 18, 19,  5, 18,  7,  8, 17,  1,  9, 18,  7,  4, 19, 14,\n",
       "        9, 17,  6, 14,  5, 16, 19,  7, 10,  4, 18, 13,  1, 10, 15,  6,  1,\n",
       "        1,  9,  6, 18,  9, 14,  6,  1, 11,  1, 14, 14,  3,  4,  3,  4, 11,\n",
       "       17, 14,  2, 11, 11,  0,  7,  1, 14,  7,  7, 19, 15, 10,  7, 12,  7,\n",
       "       14, 16,  9,  7, 13,  9,  2,  7, 14,  7,  9, 13, 16,  5, 14,  8, 15,\n",
       "       13,  9])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_prediction).to_csv('./predictions.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
